{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "from mpl_toolkits import axisartist\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择在GPU或CPU上面运行\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 拿到数据路径，方便后续读取\n",
    "dir_path = 'D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Numerical_simulation_Data\\\\train'\n",
    "# 获取目录及其子目录下所有CSV文件的路径\n",
    "dataPaths = sorted(glob.glob(os.path.join(dir_path, '**', '*.csv'), recursive=True))\n",
    "random.seed(42)\n",
    "random.shuffle(dataPaths)\n",
    "\n",
    "# 遍历读取数据\n",
    "for dataPath in dataPaths:\n",
    "    # 读取数据\n",
    "    data_1 = pd.read_csv(dataPath)\n",
    "    data.append(data_1.iloc[1:10001, 1])\n",
    "\n",
    "# 将数据和标签转换为numpy数组\n",
    "train_data = np.array(data, dtype=\"float\")\n",
    "train_labels = np.array(data, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 拿到数据路径，方便后续读取\n",
    "dir_path = 'D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Numerical_simulation_Data\\\\validation'\n",
    "# 获取目录及其子目录下所有CSV文件的路径\n",
    "dataPaths = sorted(glob.glob(os.path.join(dir_path, '**', '*.csv'), recursive=True))\n",
    "random.seed(42)\n",
    "random.shuffle(dataPaths)\n",
    "\n",
    "# 遍历读取数据\n",
    "for dataPath in dataPaths:\n",
    "    # 读取数据\n",
    "    data_1 = pd.read_csv(dataPath)\n",
    "    data.append(data_1.iloc[1:10001, 1])\n",
    "\n",
    "# 将数据和标签转换为numpy数组\n",
    "validation_data = np.array(data, dtype=\"float\")\n",
    "validation_labels = np.array(data, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas=train_data.reshape(-1,train_data.shape[1],1)\n",
    "print(train_datas.shape)\n",
    "\n",
    "validation_datas=validation_data.reshape(-1,validation_data.shape[1],1)\n",
    "print(validation_datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(train_datas[0],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(mm)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.savefig('D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\CRCM\\\\CCF\\\\train_data.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(signal, snr_db):\n",
    "    \"\"\"\n",
    "    根据信噪比（dB）为信号添加高斯噪声\n",
    "    :param signal: 原始信号\n",
    "    :param snr_db: 信噪比（dB）\n",
    "    :return: 带噪声的信号\n",
    "    \"\"\"\n",
    "    # 计算信号功率\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    \n",
    "    # 将信噪比从分贝转换为线性比例\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    \n",
    "    # 计算噪声功率\n",
    "    noise_power = signal_power / snr_linear\n",
    "    \n",
    "    # 生成高斯噪声\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n",
    "    \n",
    "    # 添加噪声\n",
    "    noisy_signal = signal + noise\n",
    "    return noisy_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加噪声，信噪比为20dB\n",
    "snr_db = 20  # 信噪比（dB）\n",
    "train_noisy_signal = add_noise_with_snr(train_datas, snr_db)\n",
    "print(f'train_noisy_signal.shape:{train_noisy_signal.shape}')\n",
    "\n",
    "validation_noisy_signal = add_noise_with_snr(validation_datas, snr_db)\n",
    "print(f'validation_noisy_signal.shape:{validation_noisy_signal.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(train_noisy_signal[0],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(mm)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.savefig('D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\CRCM\\\\CCF\\\\train_data_noise.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=10\n",
    "EPOCH = 200\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "#torch.from_numpy将 NumPy 数组转换为 PyTorch 张量\n",
    "#TensorDataset用于将张量数据和标签组合成一个数据集\n",
    "#DataLoader用于从数据集中加载批次数据，并进行训练或测试\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_noisy_signal),torch.from_numpy(train_labels))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_noisy_signal),torch.from_numpy(validation_labels))\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(x_prime,x):\n",
    "    \"\"\"\n",
    "    计算信号的信噪比（SNR）。\n",
    "\n",
    "    参数:\n",
    "        x (numpy.ndarray): 干净信号。\n",
    "        x_prime (numpy.ndarray): 噪声信号。\n",
    "\n",
    "    返回:\n",
    "        float: 信噪比，单位为 dB。\n",
    "    \"\"\"\n",
    "    # 计算信号功率\n",
    "    signal_power = torch.mean(x ** 2)\n",
    "    noise = x_prime-x\n",
    "    # 计算噪声功率\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    \n",
    "    # 计算信噪比\n",
    "    if noise_power == 0:\n",
    "        raise ValueError(\"噪声功率不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    \n",
    "    snr_1 = snr.to(device)\n",
    "    return snr_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pcc(x, y):\n",
    "    \"\"\"\n",
    "    计算两个信号的皮尔逊相关系数（PCC）。\n",
    "\n",
    "    参数:\n",
    "        x (torch.Tensor): 第一个信号，假定在 CUDA 上。\n",
    "        y (torch.Tensor): 第二个信号，假定在 CUDA 上。\n",
    "\n",
    "    返回:\n",
    "        float: 皮尔逊相关系数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    \n",
    "    # 计算协方差\n",
    "    covariance = torch.mean((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_x = torch.std(x)\n",
    "    std_y = torch.std(y)\n",
    "    \n",
    "    # 计算皮尔逊相关系数\n",
    "    if std_x == 0 or std_y == 0:\n",
    "        raise ValueError(\"标准差不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    pcc = covariance / (std_x * std_y)\n",
    "\n",
    "    pcc_1 = pcc.to(device)\n",
    "\n",
    "    return pcc_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_quantize(signal, levels):\n",
    "    # 将张量归一化到 [0, 1] 范围\n",
    "    normalized_tensor = (signal - torch.min(signal)) / (torch.max(signal) - torch.min(signal))\n",
    "    # 量化操作：将 [0, 1] 分成 levels 个区间\n",
    "    quantized_tensor = torch.round(normalized_tensor * (levels - 1)) / (levels - 1)\n",
    "    # 将量化后的张量映射回原始范围\n",
    "    quantized_tensor = quantized_tensor * (torch.max(signal) - torch.min(signal)) + torch.min(signal)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRCM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRCM, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=25, stride=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(16, 32, kernel_size=25, stride=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(32, 64, kernel_size=25, stride=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 64, kernel_size=25, stride=2, output_padding=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=25, stride=2, output_padding=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=25, stride=2, output_padding=1, padding=12),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=25, stride=1, padding=12),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.decoder(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(signal):\n",
    "    \"\"\"\n",
    "    计算批量信号的自相关函数。\n",
    "    \n",
    "    参数:\n",
    "    signal (torch.Tensor): 输入信号，形状为 [batch_size, 1, N]。\n",
    "    device (str): 指定返回张量的设备（如 'cpu' 或 'cuda'）。\n",
    "    \n",
    "    返回:\n",
    "    torch.Tensor: 自相关函数的值，形状为 [batch_size, N]。\n",
    "    \"\"\"\n",
    "    # 确保输入是 PyTorch 张量\n",
    "    if not isinstance(signal, torch.Tensor):\n",
    "        signal = torch.tensor(signal, dtype=torch.float32)\n",
    "    \n",
    "    # 将信号移动到 CPU（因为 NumPy 需要 CPU 数据）\n",
    "    signal = signal.to('cpu')\n",
    "    \n",
    "    # 去掉多余的维度 [batch_size, 1, N] -> [batch_size, N]\n",
    "    signal = signal.squeeze(1)\n",
    "    \n",
    "    # 初始化存储自相关结果的张量\n",
    "    batch_size, N = signal.shape\n",
    "    autocorr_results = torch.zeros((batch_size, N), dtype=torch.float32)\n",
    "    \n",
    "    # 对每个信号计算自相关函数\n",
    "    for i in range(batch_size):\n",
    "        # 提取当前信号\n",
    "        current_signal = signal[i].detach().cpu().numpy()\n",
    "        \n",
    "        # 减去均值，使信号零均值\n",
    "        current_signal = current_signal - np.mean(current_signal)\n",
    "        \n",
    "        # 计算自相关函数\n",
    "        autocorr = np.correlate(current_signal, current_signal, mode='full')\n",
    "        \n",
    "        # 取自相关函数的后半部分（因为自相关函数是对称的）\n",
    "        autocorr = autocorr[len(autocorr)//2:]\n",
    "        \n",
    "        # 归一化自相关函数\n",
    "        autocorr = autocorr / autocorr[0]\n",
    "        \n",
    "        # 将结果存储到张量中\n",
    "        autocorr_results[i] = torch.from_numpy(autocorr)\n",
    "    \n",
    "    # 将结果移动到指定设备\n",
    "    autocorr_results = autocorr_results.to(device)\n",
    "    results=autocorr_results.reshape(-1, 1, train_data.shape[1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRCM()\n",
    "model.to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=1e4   #损失函数放大倍数\n",
    "B=1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2,3,4,5,6,7,8]\n",
    "for k in n:\n",
    "    print(f\"Quantization level:{k}\")\n",
    "\n",
    "    #信噪比\n",
    "    train_SNR=[]\n",
    "    valid_SNR=[]\n",
    "\n",
    "    #PCC\n",
    "    train_PCC=[]\n",
    "    valid_PCC=[]\n",
    "\n",
    "    #两个空列表用于存储训练和验证中的损失值\n",
    "    train_loss_epoch=[]\n",
    "\n",
    "    #两个空列表用于存储训练和验证中的损失值\n",
    "    valid_loss_epoch=[]\n",
    "\n",
    "    #训练和验证阶段\n",
    "    for epoch in range(EPOCH):\n",
    "        if epoch % (EPOCH/10)==0:\n",
    "            print(\"-------第 {} 轮训练开始-------\".format(epoch+1)) \n",
    "\n",
    "        train_epoch = 0.0 #这段代码放在epoch循环中，每次循环时清零\n",
    "        train_SNR_2 = 0.0\n",
    "        train_PCC_2 = 0.0\n",
    "\n",
    "        # 训练步骤开始\n",
    "        model.train() #在训练模式下，模型会计算并反向传播误差，并更新模型参数   \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() #在使用优化器更新参数之前，我们需要先将模型参数的梯度清零，\n",
    "                                #以避免之前的梯度对当前梯度的影响\n",
    "            \n",
    "            x1=x.type(torch.FloatTensor)\n",
    "            y1=y.type(torch.FloatTensor)\n",
    "\n",
    "            x2,y2=x1.reshape(-1,1,train_datas.shape[1]),y1.reshape(-1,1,train_datas.shape[1])\n",
    "\n",
    "            x3,y3 = x2.to(device),y2.to(device)\n",
    "\n",
    "            # 对信号进行不同码率的量化\n",
    "            x4 = custom_quantize(x3, k)\n",
    "            y_hat = model(x4)\n",
    "\n",
    "            y_hat_CCF = autocorrelation(y_hat)\n",
    "            y3_CCF = autocorrelation(y3)\n",
    "\n",
    "            SNR_1 = calculate_snr(y_hat,y3)\n",
    "            train_SNR_2 += SNR_1*x2.size(0)\n",
    "\n",
    "            PCC_1 = calculate_pcc(y_hat,y3)\n",
    "            train_PCC_2 += PCC_1*x2.size(0)\n",
    "\n",
    "            loss_MSE = A*loss(y_hat, y3)\n",
    "            loss_CCF = B*loss(y_hat_CCF,y3_CCF)\n",
    "            train_loss = loss_MSE + loss_CCF\n",
    "            \n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch += train_loss.item() * x2.size(0)\n",
    "            \n",
    "        #计算一个 epoch 内的平均训练损失\n",
    "        train_mean_length = train_epoch / len(train_loader.dataset)\n",
    "        #将平均训练损失 train_mean_loss 添加到 train_loss_mean 列表中\n",
    "        train_loss_epoch.append([train_mean_length])\n",
    "\n",
    "        train_mean_SNR = train_SNR_2/len(train_loader.dataset)\n",
    "        train_mean_PCC = train_PCC_2/len(train_loader.dataset)\n",
    "\n",
    "        train_SNR.append(train_mean_SNR)\n",
    "        train_PCC.append(train_mean_PCC)\n",
    "\n",
    "        model.eval()\n",
    "        valid_epoch = 0.0\n",
    "        valid_SNR_2 = 0.0\n",
    "        valid_PCC_2 = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x_data, y_label) in enumerate(validation_loader):\n",
    "                \n",
    "                x1=x_data.type(torch.FloatTensor)\n",
    "                y1=y_label.type(torch.FloatTensor)\n",
    "\n",
    "                x2,y2=x1.reshape(-1,1,train_datas.shape[1]),y1.reshape(-1,1,train_datas.shape[1])\n",
    "\n",
    "                x3,y3 = x2.to(device),y2.to(device)\n",
    "\n",
    "                # 对信号进行不同码率的量化\n",
    "                x4 = custom_quantize(x3, k)\n",
    "\n",
    "                y_hat = model(x4)\n",
    "\n",
    "                y_hat_CCF = autocorrelation(y_hat)\n",
    "                y3_CCF = autocorrelation(y3)\n",
    "\n",
    "                SNR_1 = calculate_snr(y_hat,y3)\n",
    "                valid_SNR_2 += SNR_1*x2.size(0)\n",
    "\n",
    "                PCC_1 = calculate_pcc(y_hat,y3)\n",
    "                valid_PCC_2 += PCC_1*x2.size(0)\n",
    "\n",
    "                loss_MSE = A*loss(y_hat, y3)\n",
    "                loss_CCF = B*loss(y_hat_CCF,y3_CCF)\n",
    "\n",
    "                valid_loss = loss_MSE + loss_CCF\n",
    "\n",
    "                valid_epoch += valid_loss.item() * x2.size(0)\n",
    "\n",
    "            valid_mean_length = valid_epoch / len(validation_loader.dataset)\n",
    "            valid_loss_epoch.append([valid_mean_length])\n",
    "\n",
    "            valid_mean_SNR = valid_SNR_2/len(validation_loader.dataset)\n",
    "            valid_mean_PCC = valid_PCC_2/len(validation_loader.dataset)\n",
    "\n",
    "            valid_SNR.append(valid_mean_SNR)\n",
    "            valid_PCC.append(valid_mean_PCC)\n",
    "\n",
    "        if epoch % (EPOCH/10) == 0:\n",
    "            print(f\"Epoch:{epoch}, Train_Loss: {train_mean_length:.4f},Valid_Loss: {valid_mean_length:.4f}\")\n",
    "        \n",
    "    #设置图形大小、像素\n",
    "    fig=plt.figure(figsize=(10,6))\n",
    "    plt.rcParams['figure.figsize']=(10,6)\n",
    "    plt.rcParams['savefig.dpi'] = 600 #图片像素\n",
    "    plt.rcParams['figure.dpi'] = 600\n",
    "    #设置图形中坐标轴标签大小、刻度值字体及大小\n",
    "    params = {'axes.labelsize': 18, 'axes.titlesize':18, 'legend.fontsize': 14, 'xtick.labelsize': 16, 'ytick.labelsize': 16,'font.family':'Times New roman'}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "    host = host_subplot(111, axes_class=axisartist.Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "\n",
    "    par1 = host.twinx()\n",
    "    par2 = host.twinx()\n",
    "    #设置第三根Y轴位置，这里选择是右边\n",
    "    par2.axis[\"right\"] = par2.new_fixed_axis(loc=\"right\", offset=(60, 0))\n",
    "    #设置Y轴刻度值、坐标轴标签显示\n",
    "    par1.axis[\"right\"].toggle(all=True)\n",
    "    par2.axis[\"right\"].toggle(all=True)\n",
    "\n",
    "    #进行绘图\n",
    "    p1, = host.plot(train_loss_epoch, 'ro-', linewidth=2.5, label='Training loss')\n",
    "    p1, = host.plot(valid_loss_epoch, 'rs-', linewidth=2.5, label='Validation loss')\n",
    "\n",
    "    p2, = par1.plot(train_SNR, 'go-', linewidth=2.5, label='Training SNR') \n",
    "    p2, = par1.plot(valid_SNR, 'gs-', linewidth=2.5, label='Validation SNR')  \n",
    "\n",
    "    p3, = par2.plot(train_PCC, 'ko-', linewidth=2.5, label='Training PCC')  \n",
    "    p3, = par2.plot(valid_PCC, 'ks-', linewidth=2.5, label='Validation PCC')  \n",
    "    #设置x轴、y轴标签\n",
    "    host.set_xlabel(\"Epoch\")\n",
    "    host.set_ylabel(\"Loss\")\n",
    "    par1.set_ylabel(\"SNR(dB)\")\n",
    "    par2.set_ylabel(\"PCC\")\n",
    "    #显示图例\n",
    "    host.legend(frameon=False,fontsize='x-large')\n",
    "    #设置y轴标签颜色\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    par2.axis[\"right\"].label.set_color(p3.get_color())\n",
    "    #将刻度线设置为向外\n",
    "    host.axis[:].major_ticks.set_tick_out(True)\n",
    "    par1.axis[:].major_ticks.set_tick_out(True)\n",
    "    par2.axis[:].major_ticks.set_tick_out(True)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(f'D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\CRCM\\\\CCF\\\\Model_Loss_CCF_{k}.jpg', dpi=600, bbox_inches='tight')\n",
    "    #显示图形\n",
    "    plt.show()\n",
    "\n",
    "torch.save(model, f'D:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\CRCM\\\\CCF\\\\model_signal_reconstruction_CCF.pth') \n",
    "print(\"模型已保存\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
