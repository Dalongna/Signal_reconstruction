{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "from mpl_toolkits import axisartist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择在GPU或CPU上面运行\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "Ratio = 10\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 拿到数据路径，方便后续读取\n",
    "dir_path = 'E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Numerical_simulation_Data\\\\train'\n",
    "# 获取目录及其子目录下所有CSV文件的路径\n",
    "dataPaths = sorted(glob.glob(os.path.join(dir_path, '**', '*.csv'), recursive=True))\n",
    "random.seed(42)\n",
    "random.shuffle(dataPaths)\n",
    "\n",
    "# 遍历读取数据\n",
    "for dataPath in dataPaths:\n",
    "    # 读取数据\n",
    "    data_1 = pd.read_csv(dataPath)\n",
    "    data.append(data_1.iloc[1:N+1, 1])\n",
    "\n",
    "# 将数据和标签转换为numpy数组\n",
    "train_data = np.array(data, dtype=\"float\")\n",
    "train_labels = np.array(data, dtype=\"float\")\n",
    "\n",
    "# 随机挑选原数据量的1/8作为新的train_data\n",
    "random_indices = random.sample(range(len(train_data)), len(train_data) // Ratio)\n",
    "train_data = train_data[random_indices]\n",
    "train_labels = train_labels[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 拿到数据路径，方便后续读取\n",
    "dir_path = 'E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Numerical_simulation_Data\\\\validation'\n",
    "# 获取目录及其子目录下所有CSV文件的路径\n",
    "dataPaths = sorted(glob.glob(os.path.join(dir_path, '**', '*.csv'), recursive=True))\n",
    "random.seed(42)\n",
    "random.shuffle(dataPaths)\n",
    "\n",
    "# 遍历读取数据\n",
    "for dataPath in dataPaths:\n",
    "    # 读取数据\n",
    "    data_1 = pd.read_csv(dataPath)\n",
    "    data.append(data_1.iloc[1:N+1, 1])\n",
    "\n",
    "# 将数据和标签转换为numpy数组\n",
    "validation_data = np.array(data, dtype=\"float\")\n",
    "validation_labels = np.array(data, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas=train_data.reshape(-1,train_data.shape[1],1)\n",
    "print(train_datas.shape)\n",
    "\n",
    "validation_datas=validation_data.reshape(-1,validation_data.shape[1],1)\n",
    "print(validation_datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(train_datas[0],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(mm)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.savefig('E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\ISCM\\\\MSE\\\\train_data.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(signal, snr_db):\n",
    "    \"\"\"\n",
    "    根据信噪比（dB）为信号添加高斯噪声\n",
    "    :param signal: 原始信号\n",
    "    :param snr_db: 信噪比（dB）\n",
    "    :return: 带噪声的信号\n",
    "    \"\"\"\n",
    "    # 计算信号功率\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    \n",
    "    # 将信噪比从分贝转换为线性比例\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    \n",
    "    # 计算噪声功率\n",
    "    noise_power = signal_power / snr_linear\n",
    "    \n",
    "    # 生成高斯噪声\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n",
    "    \n",
    "    # 添加噪声\n",
    "    noisy_signal = signal + noise\n",
    "    return noisy_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加噪声，信噪比为20dB\n",
    "snr_db = 20  # 信噪比（dB）\n",
    "train_noisy_signal = add_noise_with_snr(train_datas, snr_db)\n",
    "print(f'train_noisy_signal.shape:{train_noisy_signal.shape}')\n",
    "\n",
    "validation_noisy_signal = add_noise_with_snr(validation_datas, snr_db)\n",
    "print(f'validation_noisy_signal.shape:{validation_noisy_signal.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(train_noisy_signal[0],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(mm)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.savefig('E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\ISCM\\\\MSE\\\\train_data_noise.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCH = 600\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "#torch.from_numpy将 NumPy 数组转换为 PyTorch 张量\n",
    "#TensorDataset用于将张量数据和标签组合成一个数据集\n",
    "#DataLoader用于从数据集中加载批次数据，并进行训练或测试\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_noisy_signal),torch.from_numpy(train_datas))\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_noisy_signal),torch.from_numpy(validation_datas))\n",
    "validation_loader = DataLoader(validation_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(x_prime,x):\n",
    "    \"\"\"\n",
    "    计算信号的信噪比（SNR）。\n",
    "\n",
    "    参数:\n",
    "        x (numpy.ndarray): 干净信号。\n",
    "        x_prime (numpy.ndarray): 噪声信号。\n",
    "\n",
    "    返回:\n",
    "        float: 信噪比，单位为 dB。\n",
    "    \"\"\"\n",
    "    # 计算信号功率\n",
    "    signal_power = torch.mean(x ** 2)\n",
    "    noise = x_prime-x\n",
    "    # 计算噪声功率\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    \n",
    "    # 计算信噪比\n",
    "    if noise_power == 0:\n",
    "        raise ValueError(\"噪声功率不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    \n",
    "    snr_1 = snr.to(device)\n",
    "    return snr_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pcc(x, y):\n",
    "    \"\"\"\n",
    "    计算两个信号的皮尔逊相关系数（PCC）。\n",
    "\n",
    "    参数:\n",
    "        x (torch.Tensor): 第一个信号，假定在 CUDA 上。\n",
    "        y (torch.Tensor): 第二个信号，假定在 CUDA 上。\n",
    "\n",
    "    返回:\n",
    "        float: 皮尔逊相关系数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    \n",
    "    # 计算协方差\n",
    "    covariance = torch.mean((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_x = torch.std(x)\n",
    "    std_y = torch.std(y)\n",
    "    \n",
    "    # 计算皮尔逊相关系数\n",
    "    if std_x == 0 or std_y == 0:\n",
    "        raise ValueError(\"标准差不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    pcc = covariance / (std_x * std_y)\n",
    "\n",
    "    pcc_1 = pcc.to(device)\n",
    "\n",
    "    return pcc_1.item()  # 将结果转换为 Python 标量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, N_target):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),  # 保持长度不变\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # 长度减半\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # 保持长度不变\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # 长度再减半\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),  # 保持长度不变\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # 长度再减半\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),  # 保持长度不变\n",
    "            nn.Tanh(),\n",
    "            nn.AdaptiveMaxPool1d(64)  # 自适应池化，确保输出长度为64\n",
    "        )\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=256, out_channels=128, kernel_size=2, stride=2),  # 长度加倍\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=2, stride=2),  # 长度加倍\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=2, stride=2),  # 长度加倍\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=1, kernel_size=2, stride=2),  # 长度加倍\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # 最后一层线性层，确保输出长度为N_target\n",
    "        self.final_linear = nn.Linear(1024, N_target)  # 输入维度调整为1024\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码过程\n",
    "        encoded = self.encoder(x)\n",
    "        # 解码过程\n",
    "        decoded = self.decoder(encoded)\n",
    "        # 调整长度到N_target\n",
    "        decoded = decoded.view(decoded.size(0), -1)  # 展平\n",
    "        decoded = self.final_linear(decoded)\n",
    "        y = decoded.view(decoded.size(0), 1, -1)  # 调整形状为 [batch_size, 1, N_target]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_signal(x, compression_ratio):\n",
    "    \"\"\"\n",
    "    对信号进行间隔取样压缩\n",
    "    :param x: 输入信号，维度为 [batch_size, 1, N]\n",
    "    :param compression_ratio: 压缩比\n",
    "    :return: 压缩后的信号，维度为 [batch_size, 1, N/compression_ratio]\n",
    "    \"\"\"\n",
    "    batch_size, channels, length = x.size()\n",
    "    indices = torch.arange(0, length, compression_ratio, device=x.device)\n",
    "    return torch.index_select(x, 2, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1   #损失函数放大倍数\n",
    "\n",
    "# 初始化模型\n",
    "target_length = N\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[2,32,16,8,4]\n",
    "for k in n:\n",
    "    print(f'Compression ratio:{k}')\n",
    "    # 重新初始化模型\n",
    "    model = Autoencoder(target_length)\n",
    "    model = model.to(device)  # 确保模型移动到正确的设备\n",
    "    # 重新初始化优化器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 替换为你的优化器配置    \n",
    "\n",
    "    #信噪比\n",
    "    train_SNR=[]\n",
    "    valid_SNR=[]\n",
    "\n",
    "    #PCC\n",
    "    train_PCC=[]\n",
    "    valid_PCC=[]\n",
    "\n",
    "    #两个空列表用于存储训练和验证中的损失值\n",
    "    train_loss_epoch=[]\n",
    "\n",
    "    #两个空列表用于存储训练和验证中的损失值\n",
    "    valid_loss_epoch=[]\n",
    "    \n",
    "    #训练和验证阶段\n",
    "    for epoch in range(EPOCH):\n",
    "        if epoch % (EPOCH/10)==0:\n",
    "            print(\"-------第 {} 轮训练开始-------\".format(epoch+1)) \n",
    "\n",
    "        train_epoch = 0.0 #这段代码放在epoch循环中，每次循环时清零\n",
    "        train_SNR_2 = 0.0\n",
    "        train_PCC_2 = 0.0\n",
    "\n",
    "        # 训练步骤开始\n",
    "        model.train() #在训练模式下，模型会计算并反向传播误差，并更新模型参数   \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() #在使用优化器更新参数之前，我们需要先将模型参数的梯度清零，\n",
    "                                #以避免之前的梯度对当前梯度的影响\n",
    "            \n",
    "            x1=x.type(torch.FloatTensor)\n",
    "            y1=y.type(torch.FloatTensor)\n",
    "\n",
    "            x2,y2=x1.reshape(-1,1,train_datas.shape[1]),y1.reshape(-1,1,train_datas.shape[1])\n",
    "\n",
    "            x3,y3 = x2.to(device),y2.to(device)\n",
    "            x4 = downsample_signal(x3,k)\n",
    "\n",
    "            y_hat = model(x4)\n",
    "\n",
    "            SNR_1 = calculate_snr(y_hat,y3)\n",
    "            train_SNR_2 += SNR_1*x2.size(0)\n",
    "\n",
    "            PCC_1 = calculate_pcc(y_hat,y3)\n",
    "            train_PCC_2 += PCC_1*x2.size(0)\n",
    "\n",
    "            train_loss = A*loss(y_hat, y3)\n",
    "            \n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch += train_loss.item() * x2.size(0)\n",
    "            \n",
    "        #计算一个 epoch 内的平均训练损失\n",
    "        train_mean_length = train_epoch / len(train_loader.dataset)\n",
    "        #将平均训练损失 train_mean_loss 添加到 train_loss_mean 列表中\n",
    "        train_loss_epoch.append([train_mean_length])\n",
    "\n",
    "        train_mean_SNR = train_SNR_2/len(train_loader.dataset)\n",
    "        train_mean_PCC = train_PCC_2/len(train_loader.dataset)\n",
    "\n",
    "        train_SNR.append(train_mean_SNR)\n",
    "        train_PCC.append(train_mean_PCC)\n",
    "\n",
    "        model.eval()\n",
    "        valid_epoch = 0.0\n",
    "        valid_SNR_2=0.0\n",
    "        valid_PCC_2=0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x_data, y_label) in enumerate(validation_loader):\n",
    "                \n",
    "                x1=x_data.type(torch.FloatTensor)\n",
    "                y1=y_label.type(torch.FloatTensor)\n",
    "\n",
    "                x2,y2=x1.reshape(-1,1,train_datas.shape[1]),y1.reshape(-1,1,train_datas.shape[1])\n",
    "\n",
    "                x3,y3 = x2.to(device),y2.to(device)\n",
    "                x4 = downsample_signal(x3,k)\n",
    "                y_hat = model(x4)\n",
    "\n",
    "                SNR_1 = calculate_snr(y_hat,y3)\n",
    "                valid_SNR_2 += SNR_1*x2.size(0)\n",
    "\n",
    "                PCC_1 = calculate_pcc(y_hat,y3)\n",
    "                valid_PCC_2 += PCC_1*x2.size(0)\n",
    "\n",
    "                valid_loss = A* loss(y_hat, y3)\n",
    "\n",
    "                valid_epoch += valid_loss.item() * x2.size(0)\n",
    "\n",
    "            valid_mean_length = valid_epoch / len(validation_loader.dataset)\n",
    "            valid_loss_epoch.append([valid_mean_length])\n",
    "\n",
    "            valid_mean_SNR = valid_SNR_2/len(validation_loader.dataset)\n",
    "            valid_mean_PCC = valid_PCC_2/len(validation_loader.dataset)\n",
    "\n",
    "            valid_SNR.append(valid_mean_SNR)\n",
    "            valid_PCC.append(valid_mean_PCC)\n",
    "\n",
    "        if epoch % (EPOCH/10) == 0:\n",
    "            print(f\"Epoch:{epoch}, Train_Loss: {train_mean_length:.4f},Valid_Loss: {valid_mean_length:.4f}\")\n",
    "            print(f\"train_mean_SNR: {train_mean_SNR:.2f},train_mean_PCC: {train_mean_PCC:.2f}\")\n",
    "            print(f\"valid_mean_SNR: {valid_mean_SNR:.2f},valid_mean_PCC: {valid_mean_PCC:.2f}\")\n",
    "\n",
    "    #设置图形大小、像素\n",
    "    fig=plt.figure(figsize=(10,6))\n",
    "    plt.rcParams['figure.figsize']=(10,6)\n",
    "    plt.rcParams['savefig.dpi'] = 600 #图片像素\n",
    "    plt.rcParams['figure.dpi'] = 600\n",
    "    #设置图形中坐标轴标签大小、刻度值字体及大小\n",
    "    params = {'axes.labelsize': 18, 'axes.titlesize':18, 'legend.fontsize': 14, 'xtick.labelsize': 16, 'ytick.labelsize': 16,'font.family':'Times New roman'}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "    host = host_subplot(111, axes_class=axisartist.Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "\n",
    "    par1 = host.twinx()\n",
    "    par2 = host.twinx()\n",
    "    #设置第三根Y轴位置，这里选择是右边\n",
    "    par2.axis[\"right\"] = par2.new_fixed_axis(loc=\"right\", offset=(60, 0))\n",
    "    #设置Y轴刻度值、坐标轴标签显示\n",
    "    par1.axis[\"right\"].toggle(all=True)\n",
    "    par2.axis[\"right\"].toggle(all=True)\n",
    "\n",
    "    #进行绘图\n",
    "    p1, = host.plot(train_loss_epoch, 'ro-', linewidth=2.5, label='Training loss')\n",
    "    p1, = host.plot(valid_loss_epoch, 'rs-', linewidth=2.5, label='Validation loss')\n",
    "\n",
    "    p2, = par1.plot(train_SNR, 'go-', linewidth=2.5, label='Training SNR') \n",
    "    p2, = par1.plot(valid_SNR, 'gs-', linewidth=2.5, label='Validation SNR')  \n",
    "\n",
    "    p3, = par2.plot(train_PCC, 'ko-', linewidth=2.5, label='Training PCC')  \n",
    "    p3, = par2.plot(valid_PCC, 'ks-', linewidth=2.5, label='Validation PCC')  \n",
    "    #设置x轴、y轴标签\n",
    "    host.set_xlabel(\"Epoch\")\n",
    "    host.set_ylabel(\"Loss\")\n",
    "    par1.set_ylabel(\"SNR(dB)\")\n",
    "    par2.set_ylabel(\"PCC\")\n",
    "    #显示图例\n",
    "    host.legend(frameon=False,fontsize='x-large')\n",
    "    #设置y轴标签颜色\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    par2.axis[\"right\"].label.set_color(p3.get_color())\n",
    "    #将刻度线设置为向外\n",
    "    host.axis[:].major_ticks.set_tick_out(True)\n",
    "    par1.axis[:].major_ticks.set_tick_out(True)\n",
    "    par2.axis[:].major_ticks.set_tick_out(True)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(f'E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\ISCM\\\\MSE\\\\Model_Loss_MSE_{k}.jpg', dpi=600, bbox_inches='tight')\n",
    "    #显示图形\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model, f'E:\\\\Desktop\\\\Python\\\\Signal_reconstruction\\\\Model\\\\ISCM\\\\MSE\\\\model_signal_reconstruction_MSE_{k}.pth') \n",
    "    print(f\"The model of the compression ratio has been saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
